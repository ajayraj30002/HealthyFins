# ============================================
# COMPLETE FISH DISEASE DETECTION SYSTEM
# Evaluation + Working Application
# ============================================

# 1. INSTALL ALL REQUIRED LIBRARIES
print("ğŸ“¦ Installing required libraries...")
!pip install tensorflow matplotlib opencv-python scikit-learn seaborn pandas numpy pillow gradio streamlit -q
!pip install pyngrok -q  # For web deployment

# 2. IMPORT LIBRARIES
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import os
import json
import random
import zipfile
import shutil
from PIL import Image
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc
from sklearn.preprocessing import label_binarize
from google.colab import files
import gradio as gr

import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

print("âœ… All libraries imported!")
print(f"TensorFlow version: {tf.__version__}")

# 3. LOAD YOUR TRAINED MODEL
def load_trained_model():
    """Load your trained model and class info"""
    print("\n" + "="*60)
    print("ğŸ” LOADING TRAINED MODEL")
    print("="*60)
    
    # Check if model files exist
    model_files = ['fish_disease_model_final.h5', 'model_info_final.json']
    
    for file in model_files:
        if not os.path.exists(file):
            print(f"âŒ {file} not found!")
            print("ğŸ“¤ Please upload your model files...")
            uploaded = files.upload()
            for filename in uploaded.keys():
                print(f"âœ… Uploaded: {filename}")
    
    # Load model
    print("\nğŸ“‚ Loading model...")
    model = load_model('fish_disease_model_final.h5')
    print("âœ… Model loaded successfully!")
    
    # Load class info
    with open('model_info_final.json', 'r') as f:
        class_info = json.load(f)
    
    class_names = class_info['class_names']
    reverse_map = class_info['reverse_label_map']
    image_size = class_info.get('image_size', 224)
    
    print(f"\nğŸ“Š Model Information:")
    print(f"  Classes: {len(class_names)}")
    print(f"  Class names: {class_names}")
    print(f"  Test accuracy: {class_info.get('test_accuracy', 'N/A')}")
    print(f"  Image size: {image_size}")
    
    return model, class_names, reverse_map, image_size

# 4. COMPREHENSIVE EVALUATION FUNCTION
def comprehensive_evaluation(model, X_test, y_test, class_names):
    """
    Comprehensive model evaluation with all metrics
    """
    print("\n" + "="*60)
    print("ğŸ“Š COMPREHENSIVE MODEL EVALUATION")
    print("="*60)
    
    # Get predictions
    print("ğŸ”„ Getting predictions...")
    y_pred_probs = model.predict(X_test, verbose=0)
    y_pred = np.argmax(y_pred_probs, axis=1)
    
    # Basic metrics
    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
    
    print(f"âœ… Test Accuracy: {test_acc*100:.2f}%")
    print(f"âœ… Test Loss: {test_loss:.4f}")
    
    # Detailed classification report
    print("\nğŸ“‹ Detailed Classification Report:")
    report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)
    
    # Convert to DataFrame for better display
    report_df = pd.DataFrame(report).transpose()
    print(report_df.to_string())
    
    # Save report to CSV
    report_df.to_csv('classification_report.csv')
    print("ğŸ’¾ Classification report saved: classification_report.csv")
    
    # Confusion Matrix
    print("\nğŸ¯ Confusion Matrix:")
    cm = confusion_matrix(y_test, y_pred)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names,
                cbar_kws={'label': 'Number of Predictions'})
    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.tight_layout()
    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()
    print("ğŸ’¾ Confusion matrix saved: confusion_matrix.png")
    
    # Per-class metrics visualization
    print("\nğŸ“ˆ Per-Class Performance Metrics:")
    
    per_class_metrics = []
    for i, class_name in enumerate(class_names):
        # Get indices for this class
        class_indices = np.where(y_test == i)[0]
        if len(class_indices) > 0:
            # Calculate accuracy for this class
            correct = np.sum(y_pred[class_indices] == i)
            total = len(class_indices)
            class_acc = correct / total if total > 0 else 0
            
            # Get precision and recall from report
            precision = report[class_name]['precision']
            recall = report[class_name]['recall']
            f1 = report[class_name]['f1-score']
            
            per_class_metrics.append({
                'Class': class_name,
                'Accuracy': f"{class_acc*100:.1f}%",
                'Precision': f"{precision*100:.1f}%",
                'Recall': f"{recall*100:.1f}%",
                'F1-Score': f"{f1*100:.1f}%",
                'Samples': total
            })
    
    metrics_df = pd.DataFrame(per_class_metrics)
    print(metrics_df.to_string(index=False))
    
    # Save metrics
    metrics_df.to_csv('per_class_metrics.csv', index=False)
    print("ğŸ’¾ Per-class metrics saved: per_class_metrics.csv")
    
    # ROC Curve (for binary or multi-class)
    if len(class_names) == 2:
        # Binary classification
        fpr, tpr, _ = roc_curve(y_test, y_pred_probs[:, 1])
        roc_auc = auc(fpr, tpr)
        
        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic (ROC) Curve')
        plt.legend(loc="lower right")
        plt.grid(True, alpha=0.3)
        plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')
        plt.show()
        print(f"ğŸ“Š AUC Score: {roc_auc:.4f}")
        
    else:
        # Multi-class ROC (one-vs-rest)
        print("\nğŸ“Š Multi-class ROC Curves:")
        
        # Binarize the labels
        y_test_bin = label_binarize(y_test, classes=range(len(class_names)))
        
        # Compute ROC for each class
        fpr = dict()
        tpr = dict()
        roc_auc = dict()
        
        for i in range(len(class_names)):
            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_probs[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])
        
        # Plot all ROC curves
        plt.figure(figsize=(10, 8))
        colors = plt.cm.rainbow(np.linspace(0, 1, len(class_names)))
        
        for i, color in zip(range(len(class_names)), colors):
            plt.plot(fpr[i], tpr[i], color=color, lw=2,
                    label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')
        
        plt.plot([0, 1], [0, 1], 'k--', lw=2)
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Multi-class ROC Curves')
        plt.legend(loc="lower right")
        plt.grid(True, alpha=0.3)
        plt.savefig('multiclass_roc.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Print AUC for each class
        for i, class_name in enumerate(class_names):
            print(f"  {class_name}: AUC = {roc_auc[i]:.4f}")
    
    # Precision-Recall Curve
    print("\nğŸ“Š Precision-Recall Curves:")
    
    if len(class_names) == 2:
        precision, recall, _ = precision_recall_curve(y_test, y_pred_probs[:, 1])
        
        plt.figure(figsize=(8, 6))
        plt.plot(recall, precision, color='blue', lw=2)
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.grid(True, alpha=0.3)
        plt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')
        plt.show()
    else:
        # Multi-class Precision-Recall
        plt.figure(figsize=(10, 8))
        colors = plt.cm.rainbow(np.linspace(0, 1, len(class_names)))
        
        for i, color in zip(range(len(class_names)), colors):
            precision, recall, _ = precision_recall_curve(
                (y_test == i).astype(int), 
                y_pred_probs[:, i]
            )
            plt.plot(recall, precision, color=color, lw=2, label=class_names[i])
        
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Multi-class Precision-Recall Curves')
        plt.legend(loc="best")
        plt.grid(True, alpha=0.3)
        plt.savefig('multiclass_pr_curve.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    # Prediction Distribution
    print("\nğŸ“Š Prediction Confidence Distribution:")
    
    confidences = np.max(y_pred_probs, axis=1)
    
    plt.figure(figsize=(10, 6))
    plt.hist(confidences, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    plt.xlabel('Prediction Confidence')
    plt.ylabel('Frequency')
    plt.title('Distribution of Prediction Confidences')
    plt.grid(True, alpha=0.3)
    plt.axvline(x=0.8, color='red', linestyle='--', label='High Confidence Threshold (0.8)')
    plt.legend()
    plt.savefig('confidence_distribution.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Calculate confidence statistics
    high_conf = np.sum(confidences >= 0.8) / len(confidences) * 100
    low_conf = np.sum(confidences < 0.5) / len(confidences) * 100
    
    print(f"  High confidence predictions (â‰¥80%): {high_conf:.1f}%")
    print(f"  Low confidence predictions (<50%): {low_conf:.1f}%")
    
    # Save all evaluation results
    evaluation_summary = {
        'test_accuracy': float(test_acc),
        'test_loss': float(test_loss),
        'per_class_metrics': per_class_metrics,
        'high_confidence_percentage': float(high_conf),
        'low_confidence_percentage': float(low_conf),
        'average_confidence': float(np.mean(confidences))
    }
    
    with open('evaluation_summary.json', 'w') as f:
        json.dump(evaluation_summary, f, indent=2)
    
    print("\nğŸ’¾ All evaluation results saved!")
    
    return test_acc, report_df, metrics_df

# 5. PREDICTION FUNCTION FOR NEW IMAGES
def predict_fish_disease(image_path, model, class_names, reverse_map, image_size=224):
    """
    Predict disease from a single image
    """
    # Load and preprocess image
    img = cv2.imread(image_path)
    if img is None:
        return None, None, None
    
    original_img = img.copy()
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (image_size, image_size))
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    
    # Predict
    predictions = model.predict(img, verbose=0)[0]
    predicted_class = np.argmax(predictions)
    confidence = predictions[predicted_class] * 100
    disease_name = reverse_map[str(predicted_class)]
    
    # Get top 3 predictions
    top3_idx = np.argsort(predictions)[-3:][::-1]
    top3_diseases = [reverse_map[str(idx)] for idx in top3_idx]
    top3_confidences = [predictions[idx] * 100 for idx in top3_idx]
    
    result = {
        'predicted_disease': disease_name,
        'confidence': confidence,
        'all_predictions': dict(zip(class_names, predictions * 100)),
        'top3_predictions': list(zip(top3_diseases, top3_confidences)),
        'original_image': original_img
    }
    
    return result

# 6. CREATE WEB INTERFACE WITH GRADIO
def create_web_interface(model, class_names, reverse_map, image_size):
    """
    Create a web interface for the fish disease detection system
    """
    print("\n" + "="*60)
    print("ğŸŒ CREATING WEB INTERFACE")
    print("="*60)
    
    def predict_interface(image):
        """Interface prediction function"""
        # Convert PIL image to numpy
        img_np = np.array(image)
        
        # Save temporarily
        temp_path = "temp_prediction.jpg"
        cv2.imwrite(temp_path, cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR))
        
        # Predict
        result = predict_fish_disease(temp_path, model, class_names, reverse_map, image_size)
        
        if result is None:
            return "Error: Could not process image", None
        
        # Clean up
        if os.path.exists(temp_path):
            os.remove(temp_path)
        
        # Create result string
        result_text = f"ğŸ¥ **DIAGNOSIS:** {result['predicted_disease']}\n"
        result_text += f"ğŸ“Š **CONFIDENCE:** {result['confidence']:.1f}%\n\n"
        result_text += "ğŸ” **TOP 3 PREDICTIONS:**\n"
        for disease, conf in result['top3_predictions']:
            result_text += f"  â€¢ {disease}: {conf:.1f}%\n"
        
        # Add treatment recommendations
        result_text += "\nğŸ’Š **RECOMMENDED TREATMENT:**\n"
        treatments = {
            'Healthy Fish': "âœ… Fish appears healthy. Continue regular maintenance.",
            'Bacterial diseases - Aeromoniasis': "1. Oxytetracycline (medicated feed)\n2. Florfenicol (as per vet guidance)\n3. Potassium permanganate (KMnOâ‚„): 2 mg/L",
            'Bacterial gill disease': "1. Oxytetracycline feed (50 mg/kg/day Ã— 5â€“7 days)\n2. Salt treatment: 2â€“3 g/L (short bath)\n3. Reduce ammonia & organic load",
            'Bacterial Red disease': "1. Use antifungal medication\n2. Improve water quality\n3. Increase temperature slightly",
            'bacterial': "1. Antibacterial medication\n2. Improve filtration\n3. Regular water changes",
            'parasite': "1. Anti-parasitic medication\n2. Quarantine affected fish\n3. Clean tank thoroughly"
        }
        
        # Find matching treatment
        disease_lower = result['predicted_disease'].lower()
        treatment = "Consult a veterinarian for proper diagnosis and treatment."
        
        for key, value in treatments.items():
            if key in disease_lower:
                treatment = value
                break
        
        result_text += treatment
        
        return result_text, result['original_image']
    
    # Create Gradio interface
    interface = gr.Interface(
        fn=predict_interface,
        inputs=gr.Image(label="Upload Fish Image", type="pil"),
        outputs=[
            gr.Textbox(label="Diagnosis Results", lines=15),
            gr.Image(label="Processed Image", type="numpy")
        ],
        title="ğŸŸ HealthyFins - Fish Disease Detection System",
        description="Upload an image of a fish to detect diseases and get treatment recommendations.",
        theme="soft",
        examples=[
            ["sample_fish.jpg"] if os.path.exists("sample_fish.jpg") else None
        ]
    )
    
    return interface

# 7. BATCH PREDICTION SYSTEM
def batch_predict(dataset_folder, model, class_names, reverse_map, image_size=224):
    """
    Process multiple images in a folder
    """
    print(f"\nğŸ” Processing batch predictions for: {dataset_folder}")
    
    results = []
    image_files = []
    
    # Find all images
    for root, dirs, files in os.walk(dataset_folder):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                image_files.append(os.path.join(root, file))
    
    print(f"ğŸ“Š Found {len(image_files)} images")
    
    # Process each image
    for i, img_path in enumerate(image_files):
        if i % 10 == 0 and i > 0:
            print(f"  Processed {i}/{len(image_files)} images...")
        
        result = predict_fish_disease(img_path, model, class_names, reverse_map, image_size)
        
        if result:
            results.append({
                'image_path': img_path,
                'filename': os.path.basename(img_path),
                'predicted_disease': result['predicted_disease'],
                'confidence': result['confidence'],
                'top_prediction': result['top3_predictions'][0] if result['top3_predictions'] else None
            })
    
    # Create results DataFrame
    results_df = pd.DataFrame(results)
    
    if len(results_df) > 0:
        # Save to CSV
        results_df.to_csv('batch_predictions.csv', index=False)
        print(f"ğŸ’¾ Batch predictions saved: batch_predictions.csv")
        
        # Summary statistics
        print(f"\nğŸ“Š Batch Prediction Summary:")
        print(f"  Total images processed: {len(results_df)}")
        print(f"  Most common diagnosis: {results_df['predicted_disease'].mode().iloc[0] if len(results_df) > 0 else 'N/A'}")
        print(f"  Average confidence: {results_df['confidence'].mean():.1f}%")
        
        # Disease distribution
        disease_dist = results_df['predicted_disease'].value_counts()
        print(f"\nğŸ“ˆ Disease Distribution:")
        for disease, count in disease_dist.items():
            percentage = (count / len(results_df)) * 100
            print(f"  {disease}: {count} images ({percentage:.1f}%)")
    
    return results_df

# 8. CREATE COMPLETE REPORT
def generate_comprehensive_report(model, X_test, y_test, class_names):
    """
    Generate a comprehensive PDF/HTML report
    """
    print("\n" + "="*60)
    print("ğŸ“„ GENERATING COMPREHENSIVE REPORT")
    print("="*60)
    
    # Create HTML report
    html_report = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>HealthyFins - Fish Disease Detection System Report</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; }
            h1 { color: #2c3e50; }
            h2 { color: #3498db; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
            .metric-box { 
                background: #f8f9fa; 
                padding: 20px; 
                margin: 20px 0; 
                border-radius: 10px; 
                box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            }
            .highlight { color: #e74c3c; font-weight: bold; }
            .good { color: #27ae60; }
            .warning { color: #f39c12; }
            table { width: 100%; border-collapse: collapse; margin: 20px 0; }
            th, td { padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }
            th { background-color: #3498db; color: white; }
            tr:hover { background-color: #f5f5f5; }
        </style>
    </head>
    <body>
        <h1>ğŸŸ HealthyFins - Fish Disease Detection System</h1>
        <h2>ğŸ“Š Model Evaluation Report</h2>
    """
    
    # Get predictions for report
    y_pred_probs = model.predict(X_test, verbose=0)
    y_pred = np.argmax(y_pred_probs, axis=1)
    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
    
    # Add metrics
    html_report += f"""
    <div class="metric-box">
        <h3>Overall Performance</h3>
        <p><span class="highlight">Test Accuracy:</span> <span class="good">{test_acc*100:.2f}%</span></p>
        <p><span class="highlight">Test Loss:</span> {test_loss:.4f}</p>
        <p><span class="highlight">Number of Classes:</span> {len(class_names)}</p>
        <p><span class="highlight">Test Samples:</span> {len(X_test)}</p>
    </div>
    
    <h3>Class Information</h3>
    <ul>
    """
    
    for class_name in class_names:
        html_report += f"<li>{class_name}</li>\n"
    
    html_report += """
    </ul>
    
    <h3>Recommendations for Deployment</h3>
    <div class="metric-box">
        <ol>
            <li><strong>Mobile App Development:</strong> Convert model to TensorFlow Lite for mobile deployment</li>
            <li><strong>API Service:</strong> Deploy as REST API using Flask/FastAPI</li>
            <li><strong>Database Integration:</strong> Store prediction history and farm data</li>
            <li><strong>Real-time Monitoring:</strong> Integrate with IoT sensors for water quality</li>
            <li><strong>Farmer Training:</strong> Create user-friendly interface with local language support</li>
        </ol>
    </div>
    
    <h3>Next Steps</h3>
    <div class="metric-box">
        <ul>
            <li>âœ… Model training completed</li>
            <li>âœ… Model evaluation completed</li>
            <li>ğŸ“± Develop mobile application</li>
            <li>ğŸŒ Create web dashboard</li>
            <li>ğŸ¤ Partner with local fish farms for testing</li>
            <li>ğŸ“ˆ Continuous model improvement with more data</li>
        </ul>
    </div>
    
    <p><em>Generated on: """ + pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S") + """</em></p>
    </body>
    </html>
    """
    
    # Save HTML report
    with open('healthyfins_report.html', 'w') as f:
        f.write(html_report)
    
    print("âœ… Comprehensive report generated: healthyfins_report.html")
    
    # Also create a simple text report
    text_report = f"""
    ============================================
    HEALTHYFINS - FISH DISEASE DETECTION SYSTEM
    ============================================
    
    MODEL EVALUATION REPORT
    ========================
    
    Overall Performance:
    - Test Accuracy: {test_acc*100:.2f}%
    - Test Loss: {test_loss:.4f}
    - Number of Classes: {len(class_names)}
    - Test Samples: {len(X_test)}
    
    Classes Detected: {', '.join(class_names)}
    
    RECOMMENDATIONS FOR DEPLOYMENT:
    1. Mobile App: Convert to TensorFlow Lite for Android/iOS
    2. Web Interface: Create simple upload interface
    3. Integration: Connect with farm management systems
    4. Alerts: Implement SMS/email notifications for critical diseases
    
    NEXT STEPS:
    1. Collect more diverse fish images
    2. Add regional disease variations
    3. Create multilingual interface
    4. Partner with veterinary experts
    
    Report generated: {pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")}
    """
    
    with open('healthyfins_report.txt', 'w') as f:
        f.write(text_report)
    
    print("âœ… Text report generated: healthyfins_report.txt")
    
    return html_report

# 9. MAIN EVALUATION AND SYSTEM BUILDING
def main_system():
    """
    Main function to evaluate model and build complete system
    """
    print("="*70)
    print("ğŸŸ HEALTHYFINS - COMPLETE SYSTEM EVALUATION & DEPLOYMENT")
    print("="*70)
    
    # Step 1: Load trained model
    model, class_names, reverse_map, image_size = load_trained_model()
    
    # Step 2: Ask if user has test data for evaluation
    print("\n" + "="*60)
    print("ğŸ“Š MODEL EVALUATION OPTIONS")
    print("="*60)
    
    print("Choose evaluation option:")
    print("1. Use existing test data (if available)")
    print("2. Upload new test dataset")
    print("3. Skip evaluation, go to system building")
    
    choice = input("\nEnter your choice (1-3): ").strip()
    
    X_test, y_test = None, None
    
    if choice == '1':
        # Check for existing test data
        if os.path.exists('X_test.npy') and os.path.exists('y_test.npy'):
            X_test = np.load('X_test.npy')
            y_test = np.load('y_test.npy')
            print("âœ… Loaded existing test data")
        else:
            print("âŒ No existing test data found")
            choice = '2'  # Fall back to option 2
    
    if choice == '2':
        print("\nğŸ“¤ Please upload your test dataset ZIP file...")
        uploaded = files.upload()
        
        zip_filename = None
        for filename in uploaded.keys():
            if filename.endswith('.zip'):
                zip_filename = filename
                break
        
        if zip_filename:
            # Extract test data
            test_dir = 'test_dataset'
            if os.path.exists(test_dir):
                shutil.rmtree(test_dir)
            
            os.makedirs(test_dir, exist_ok=True)
            
            with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
                zip_ref.extractall(test_dir)
            
            print("âœ… Test dataset extracted")
            
            # Load test images (simplified)
            test_images = []
            test_labels = []
            
            for class_idx, class_name in enumerate(class_names):
                class_path = os.path.join(test_dir, class_name)
                if os.path.exists(class_path):
                    for img_file in os.listdir(class_path)[:50]:  # Limit to 50 per class
                        if img_file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                            img_path = os.path.join(class_path, img_file)
                            img = cv2.imread(img_path)
                            if img is not None:
                                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                                img = cv2.resize(img, (image_size, image_size))
                                img = img / 255.0
                                test_images.append(img)
                                test_labels.append(class_idx)
            
            if test_images:
                X_test = np.array(test_images)
                y_test = np.array(test_labels)
                print(f"âœ… Loaded {len(X_test)} test images")
            else:
                print("âŒ Could not load test images")
    
    # Step 3: Run evaluation if we have test data
    if X_test is not None and y_test is not None:
        print("\n" + "="*60)
        print("ğŸ“ˆ RUNNING COMPREHENSIVE EVALUATION")
        print("="*60)
        
        test_acc, report_df, metrics_df = comprehensive_evaluation(
            model, X_test, y_test, class_names
        )
        
        # Save test data for future use
        np.save('X_test_evaluation.npy', X_test)
        np.save('y_test_evaluation.npy', y_test)
        print("ğŸ’¾ Test data saved for future use")
    
    # Step 4: Test prediction on single image
    print("\n" + "="*60)
    print("ğŸ” TEST SINGLE IMAGE PREDICTION")
    print("="*60)
    
    test_choice = input("Would you like to test the model on a single image? (yes/no): ").lower()
    
    if test_choice == 'yes':
        print("\nğŸ“¤ Please upload a fish image for testing...")
        uploaded = files.upload()
        
        for filename in uploaded.keys():
            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                print(f"\nğŸ” Testing image: {filename}")
                
                # Save the uploaded file
                with open(filename, 'wb') as f:
                    f.write(uploaded[filename])
                
                # Predict
                result = predict_fish_disease(filename, model, class_names, reverse_map, image_size)
                
                if result:
                    print(f"\nâœ… PREDICTION RESULTS:")
                    print(f"  Disease: {result['predicted_disease']}")
                    print(f"  Confidence: {result['confidence']:.1f}%")
                    print(f"\nğŸ” Top 3 Predictions:")
                    for disease, conf in result['top3_predictions']:
                        print(f"  - {disease}: {conf:.1f}%")
                
                # Clean up
                if os.path.exists(filename):
                    os.remove(filename)
                
                break
    
    # Step 5: Create web interface
    print("\n" + "="*60)
    print("ğŸŒ LAUNCHING WEB INTERFACE")
    print("="*60)
    
    web_choice = input("Would you like to launch a web interface? (yes/no): ").lower()
    
    if web_choice == 'yes':
        interface = create_web_interface(model, class_names, reverse_map, image_size)
        
        print("\nğŸš€ Starting web interface...")
        print("ğŸ“¡ The interface will be available at the displayed URL")
        print("ğŸ“± You can upload fish images through the web interface")
        
        # Launch in Colab
        interface.launch(share=True, debug=True)
    
    # Step 6: Batch prediction option
    print("\n" + "="*60)
    print("ğŸ“¦ BATCH PREDICTION SYSTEM")
    print("="*60)
    
    batch_choice = input("Would you like to process multiple images? (yes/no): ").lower()
    
    if batch_choice == 'yes':
        print("\nğŸ“¤ Please upload a ZIP file with multiple images...")
        uploaded = files.upload()
        
        for filename in uploaded.keys():
            if filename.endswith('.zip'):
                # Extract batch data
                batch_dir = 'batch_images'
                if os.path.exists(batch_dir):
                    shutil.rmtree(batch_dir)
                
                os.makedirs(batch_dir, exist_ok=True)
                
                with zipfile.ZipFile(filename, 'r') as zip_ref:
                    zip_ref.extractall(batch_dir)
                
                print("âœ… Batch images extracted")
                
                # Run batch prediction
                results_df = batch_predict(batch_dir, model, class_names, reverse_map, image_size)
                
                if len(results_df) > 0:
                    print("\nğŸ“¥ Downloading batch results...")
                    files.download('batch_predictions.csv')
                
                break
    
    # Step 7: Generate comprehensive report
    print("\n" + "="*60)
    print("ğŸ“„ GENERATING FINAL REPORT")
    print("="*60)
    
    # Use available test data or create dummy for report
    if X_test is None:
        # Create dummy test data for report
        X_test_dummy = np.random.rand(10, image_size, image_size, 3)
        y_test_dummy = np.random.randint(0, len(class_names), 10)
    else:
        X_test_dummy = X_test[:10] if len(X_test) > 10 else X_test
        y_test_dummy = y_test[:10] if len(y_test) > 10 else y_test
    
    generate_comprehensive_report(model, X_test_dummy, y_test_dummy, class_names)
    
    # Download all reports
    print("\nğŸ“¥ Downloading all reports and files...")
    report_files = [
        'healthyfins_report.html',
        'healthyfins_report.txt',
        'classification_report.csv',
        'per_class_metrics.csv',
        'confusion_matrix.png'
    ]
    
    for file in report_files:
        if os.path.exists(file):
            files.download(file)
    
    # Final message
    print("\n" + "="*70)
    print("ğŸ‰ SYSTEM EVALUATION COMPLETE!")
    print("="*70)
    print("\nğŸ“‹ WHAT YOU HAVE NOW:")
    print("  1. âœ… Trained model with evaluation metrics")
    print("  2. ğŸ“Š Comprehensive performance reports")
    print("  3. ğŸŒ Web interface (if launched)")
    print("  4. ğŸ“¦ Batch prediction capability")
    print("  5. ğŸ“„ Deployment-ready documentation")
    print("\nğŸš€ NEXT STEPS FOR DEPLOYMENT:")
    print("  1. Convert model to TensorFlow Lite for mobile")
    print("  2. Create Flutter/React Native mobile app")
    print("  3. Deploy web API using Flask/FastAPI")
    print("  4. Integrate with farm management systems")
    print("  5. Add IoT sensor data for comprehensive monitoring")
    print("\nğŸŸ Happy fishing with HealthyFins!")
    print("="*70)

# 10. RUN THE COMPLETE SYSTEM
if __name__ == "__main__":
    # Set random seeds for reproducibility
    np.random.seed(42)
    random.seed(42)
    
    # Run the complete system
    main_system()